---
title: "Retrieve API Keys"
sidebar_position: 4
slug: "/docs/ai-assistants/api-keys"
---
# How to get API Keys for h@llo.ai usage

# OpenAI

1. **Create your personal OpenAI account** at https://platform.openai.com.
You will need to verify your email before you can login and retrieve your API key.
2. Go to https://platform.openai.com/api-keys

3. Click the "Create new secret key" button and create a key with the default options. Make sure to copy that key, you won't be able to view it again later (but you can create as many as you want)

4. Make sure to set a spending limit on https://platform.openai.com/settings/organization/limits.

5. It is recommended to add at least $5 credit to your account to get into the higher API usage Tier (see https://platform.openai.com/docs/guides/rate-limits/free-tier-rate-limits)

# Anthropic

1. Create an Anthropic Console account via https://console.anthropic.com/

2. Login and navigate to the API Key section: https://console.anthropic.com/settings/keys

3. Generate a new key by clicking the **Create Key** button. Make sure to copy that key as you won't be able to view it again later. (But you can always delete and create new keys)

4. Set spending limit on https://console.anthropic.com/settings/limits (to make sure you never pay more than what you expected)

5. Top up your account balance on https://console.anthropic.com/settings/billing.

# Apple Foundation Models (on-device)

Starting with macOS 26, BetterTouchTool supports Apple's on-device Foundation Models. This runs AI inference entirely on your Mac — no API key, no cloud, no data leaving your device.

**Requirements:**
- macOS 26 (Tahoe) or later
- Apple Silicon Mac (M1 or newer recommended)

**Setup:**
1. In your assistant configuration, select **Apple Foundation Models** as the API type.
2. No API key or URL is needed — the model runs locally via Apple's `FoundationModels` framework.

**Limitations:**
- Smaller context window (~4K tokens) compared to cloud models
- Tool support is more limited than cloud providers
- Model capabilities depend on your hardware

# Claude Code CLI

BetterTouchTool can use the Claude Code CLI as a local AI backend. This runs Claude via the `claude` command-line tool as a subprocess, with tools exposed via an MCP server.

**Requirements:**
- The `claude` CLI must be installed (e.g., `npm install -g @anthropic-ai/claude-code`)
- A valid Anthropic API key configured in the CLI

**Setup:**
1. Install the Claude CLI: `npm install -g @anthropic-ai/claude-code`
2. In your assistant configuration, select **Claude CLI** as the API type.
3. No separate API key is needed in BetterTouchTool — the CLI uses its own authentication.

BetterTouchTool will search for the `claude` binary in common locations (`~/.local/bin/claude`, `/usr/local/bin/claude`, `/opt/homebrew/bin/claude`). You can also specify a custom path in the extra parameters.

# Groq

1. Go to https://console.groq.com/keys and login
2. Click the create API Key button. Make sure to copy that key as you won't be able to view it again later. (But you can always delete and create new keys)
3. Use https://api.groq.com/openai/v1/chat/completions as API url

# Google Gemini

1. Login at https://aistudio.google.com/app/apikey with your Google account

2. Click "Get an API key", agree to the terms and then create a new API key. Make sure to copy the key as you won't be able to view it again later.

3. Note: AFAIK Google Gemini doesn't allow to set a spending limit so be careful with that. (Please correct me if I'm wrong - andreas@folivora.ai)

The OpenAI compatible API URL for Gemini is https://generativelanguage.googleapis.com/v1beta/openai/v1/chat/completions



# LM Studio (local models)

Download LM Studio from https://lmstudio.ai and install it. After starting the software, select a model you want to use and download it.

You don't need an API key, however you need to select the API url. For LM Studio the default OpenAI compatible URL is http://127.0.0.1:1234/v1/chat/completions

# Ollama (local models)

Download Ollama from https://ollama.com/ and install it. After starting the software, select a model you want to use and download it.

You don't need an API key, however you need to select the API url. For ollama the default OpenAI compatible URL is http://localhost:11434/v1/chat/completions

# OpenRouter

This is a service that allows you to access most AI models through one API. For more details see

https://openrouter.ai

# Other OpenAI-compatible providers

Any provider that offers an OpenAI-compatible API endpoint can be used with h@llo.ai. This includes services like xAI (Grok), Together AI, Fireworks, and many others. Simply select the **OpenAI** API type, enter your API key, and set the provider's API URL.
